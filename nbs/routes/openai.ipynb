{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| default_exp routes.openai"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# OpenAI Routes\n",
                "> Default description (change me)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| export\n",
                "from openai import AsyncOpenAI\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| exporti\n",
                "from dataclasses import dataclass\n",
                "from typing import Union, Dict, List, Literal\n",
                "\n",
                "import json\n",
                "import os\n",
                "\n",
                "from agent_mafia.client.ResponseGetData import ResponseGetDataOpenAi\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#|export \n",
                "\n",
                "default_async_openai_client: AsyncOpenAI = AsyncOpenAI(\n",
                "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
                ")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "model = \"gpt-4o-mini-2024-07-18\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| export\n",
                "\n",
                "@dataclass\n",
                "class ChatMessage:\n",
                "    \"\"\"Format of messages setn to the browser/API\"\"\"\n",
                "\n",
                "    role: Literal[\"user\", \"model\"]\n",
                "    content: str\n",
                "    timestamp: str = None\n",
                "\n",
                "    def to_json(self):\n",
                "        return {\n",
                "            \"role\": self.role,\n",
                "            \"content\": self.content,\n",
                "            \"timestamp\": self.timestamp\n",
                "        }\n",
                "\n",
                "async def generate_openai_chat(\n",
                "    async_client: AsyncOpenAI,\n",
                "    messages : List[ChatMessage],\n",
                "    model: str = None, # llm model to use\n",
                "    response_format: Union[Dict[str, str], None] = None,\n",
                "    return_raw: bool = False,\n",
                "):\n",
                "    clean_message = [ msg.to_json() if isinstance(msg, ChatMessage) else msg for msg in messages]\n",
                "\n",
                "    res = await async_client.chat.completions.create(\n",
                "        model=model, messages=clean_message, response_format=response_format\n",
                "    )\n",
                "\n",
                "    rgd = ResponseGetDataOpenAi.from_res(res)\n",
                "\n",
                "    if return_raw:\n",
                "        return rgd\n",
                "\n",
                "    content = res.choices[0].message.content\n",
                "    rgd.response = content\n",
                "\n",
                "    if response_format and response_format.get(\"type\") == \"json_object\":\n",
                "        rgd.response = json.loads(content)\n",
                "\n",
                "    return rgd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Hello, Jae! How can I assist you today?'"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "(await generate_openai_chat(\n",
                "        async_client = default_async_openai_client,\n",
                "        messages = [ChatMessage(role = 'user', content = 'hello, my name is jae', )],\n",
                "        model = model, \n",
                "        return_raw = False)).response"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| export\n",
                "async def generate_openai_embbedding(\n",
                "    text,\n",
                "    async_client: AsyncOpenAI = None,\n",
                "    model=\"text-embedding-3-small\",\n",
                "    return_raw: bool = False,\n",
                "    debug_prn: bool = False,\n",
                ") -> List[float]:\n",
                "\n",
                "    if debug_prn:\n",
                "        print(\"ðŸ“š - starting LLM\")\n",
                "\n",
                "    async_client = async_client or default_async_openai_client\n",
                "\n",
                "    res = await async_client.embeddings.create(model=model, input=text)\n",
                "\n",
                "    if return_raw:\n",
                "        return res\n",
                "\n",
                "    return res.data[0].embedding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| hide\n",
                "nbdev.nbdev_export('/openai.ipynb')"
            ]
        }
    ],
    "metadata": {
        "jupytext": {
            "split_at_heading": true
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
