{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| default_exp routes.storage"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Storage Routes\n",
                "> Default description (change me)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| export\n",
                "from supabase import create_client\n",
                "from supabase import Client as SupabaseClient\n",
                "\n",
                "\n",
                "import agent_mafia.utils.files as amfi\n",
                "import json\n",
                "import datetime as dt\n",
                "\n",
                "from agent_mafia.client.ResponseGetData import ResponseGetDataSupabase"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| hide\n",
                "import os\n",
                "import nbdev"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "supabase_client : SupabaseClient = create_client(\n",
                "    os.environ[\"SUPABASE_URL\"], \n",
                "    os.environ[\"SUPABASE_SERVICE_KEY\"]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| export\n",
                "def store_data_in_supabase_table(\n",
                "    supabase_client: SupabaseClient,\n",
                "    table_name : str,\n",
                "    data: dict,\n",
                "):\n",
                "    \"\"\"stores data into a supabase table\"\"\"\n",
                "    res = (\n",
                "        supabase_client.table(table_name)\n",
                "        .upsert(data, on_conflict=\"url, chunk_number\")\n",
                "        .execute()\n",
                "    )\n",
                "\n",
                "    rgd = ResponseGetDataSupabase.from_res(res = res)\n",
                "\n",
                "    return rgd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'id': 2506,\n",
                            "  'url': 'test.md',\n",
                            "  'chunk_number': 0,\n",
                            "  'title': 'Domo IT Whitepaper',\n",
                            "  'summary': 'a whitepaper a about IT',\n",
                            "  'content': '# Executive Summary\\n\\nIT departments have invested heavily in people and systems to \\xa0get closer to the fundamental goal of unlocking the right data, \\xa0at the right time, for the right people. But to date, businesses \\xa0have been forced to cobble together disparate efforts, with no \\xa0single solution able to deliver the combination of functionality, \\xa0security, and ease of use required to bring data efficiently to \\xa0everyone within an organization. This paper explores what \\xa0makes Domo’s solution different, how it solves common \\xa0challenges faced by IT departments, and how Domo offers a \\xa0data strategy built for enterprise but designed for people.\\n\\nLearn how Domo:\\n\\n- Functions as much more than just another BI or visualization tool. + Complements, rather than threatens, your existing infrastructure and systems. + Brings trusted security, risk mitigation, and governance to your data and people. + Offers several implementation options to find the best cost value fit and trade-off for your unique situation.\\n\\n- Provides extensibility, agility, and scale that grows with your business, coupled with an efficiency that prevents unnecessary duplication of data.\\n\\nIn short, Domo understands not just data but also the daily \\xa0people and culture challenges faced by IT departments. \\xa0The amount of data that needs to be managed continues to \\xa0increase but so do pressures to reduce costs and become \\xa0more efficient. Read on to see how Domo can help IT create a \\xa0digitally connected organization that fosters innovation while \\xa0also bringing advanced governance and security.\\n\\n# Why Domo Matters in \\xa0Today’s Landscape\\n\\n## The Growth of Shadow IT\\n\\nIt’s no secret that data continues to grow exponentially yet IT budgets have remained relatively \\xa0flat. This dichotomy of growing data but stagnant resources creates frustration with scale, \\xa0integration, and adoption. Meanwhile, marketing clouds, sales clouds, and HR clouds have \\xa0emerged to capture divisional budgets and decrease the storage costs of legacy on-premises \\xa0systems. Unfortunately, they often start as shadow IT and result in complex siloed systems that \\xa0hinder wide user adoption, are complicated to maintain, and pose additional security complications.\\n\\n## The Limitations of Data Warehouses and Data Lakes\\n\\nMany enterprises still rely on data warehouses to store structured data from each department \\xa0in hierarchical folders, and data warehouses can still be useful for production applications that \\xa0require especially tight security. But the explosion of data has put pressure on traditional \\xa0warehouses. Few warehouses are suited to manage the ever-expanding variety and volume of \\xa0data in today’s environment. A data warehouse is simply too expensive and inflexible to scale \\xa0with emerging demands.\\n\\nData lakes attempt to address these issues by making infrastructure more agile, enabling IT \\xa0leaders to maintain a single source of raw data, and providing multiple versions of specialized \\xa0exports. However, while data lakes can house very large amounts of data in a cost-effective \\xa0manner, they are not generally built for query speed. Even basic joins can be very slow. It is great \\xa0to have all the data in one place, but it is hard to get it out efficiently when you have to rely on \\xa0scarce engineering resources or expensive data scientists.\\n\\nMoreover, a data lake is often built before first determining the best ways to fill it and structure \\xa0it. When a data lake is designed as one entity rather than partitioned to address different types \\xa0of use cases, it can easily turn from a lake into a swamp of stagnant and ignored information. \\xa0Domo’s\\xa0flexible infrastructure supports incremental evolution of the data lake to assure maxi mum utility. Domo Connectors and Domo Workbench help pull data in from legacy systems while \\xa0the data lake is setup. Once the data lake contains the new required data, the data in Domo can \\xa0be swapped to the new source by direct upload or by taking the federated caching approach \\xa0documented below. The end user in the business does not have to change tools or even know \\xa0that back end systems have changed.\\n\\n## Domo as a Data Mart to Augment Existing Investment\\n\\nAs enterprises deal with complicated governance across their tech stack, IT leadership is \\xa0more important than ever. Many have found traction in this digital transformation by taking \\xa0advantage of Domo’s differentiated fit as a rapid prototyping data mart to quickly test \\xa0what is useful enough to justify inclusion in the data lake. Domo’s approach saves costs by \\xa0consolidating systems across connection, transformation, and visualization that formerly \\xa0required separate contracts and maintenance.\\n\\n![](images/image1.png)\\n\\nInstead of a rip-and-replace solution, Domo can be used as a highly flexible data mart that \\xa0functions as a capstone overlay to your current systems. Domo builds on the strong foundation \\xa0you’ve already created, letting you leverage your current architecture by safely extending access \\xa0and significantly improving adoption of IT investments across the whole company.\\n\\n## Fueling Exploration with a Data Mart Approach\\n\\nWe also know that not every single business problem requires or warrants data being added to \\xa0your data lake. Domo connectors help with areas that are of smaller importance or outside the \\xa0core of the data lake scope. Domo’s intuitive interface is easily adopted by users across all \\xa0departments and helps accelerate innovation and experimentation. While helping proactive \\xa0individuals become more agile, Domo still respects the need for administrative control.\\xa0 Personalized data permissions deliver fast answers while limiting access of sensitive data to \\xa0authorized users. In this way, Domo can prove the usefulness of new data that should be added to \\xa0the data lake, help eliminate data that would not be useful in the lake, and help define prioritization.\\n\\nBecause it is intuitive enough to be used by knowledge workers in every department, Domo grows \\xa0faster than any other data mart. Business users can quickly automate imports from formerly \\xa0scattered systems and build independence in final mile business intelligence while IT refocuses \\xa0on more strategic initiatives. By showing the flow of data across all systems within your estab lished data lake, Domo helps IT leaders root out shadow IT and prevent rogue data sets from \\xa0propagating in silos. Governance finally becomes realistic as IT leaders gain the control they need.\\n\\n# How Domo Connects \\xa0and Stores Your Data\\n\\n## Simplify Data Access for Critical Decisions\\n\\nConnect is Domo’s bi-directional framework that includes over 500 full-scale proprietary \\xa0plug-and-play connectors. Users in any department can easily bring in data whether it resides in \\xa0the cloud, on-premises, or in local files. Domo can easily ingest multi-billion row datasets across \\xa0high bandwidth connections. This eliminates the time-consuming and costly processes of \\xa0building and maintaining data connections with internal engineering resources. Data automatically \\xa0updates so you can track time-sensitive trends and see performance unfold in real time.\\n\\n![](images/image3.png)![](images/image2.png)For businesses that have spent billions of dollars on legacy on-premise data centers, or ones that \\xa0are in highly-regulated industries with data like PII and PHI that need special handling, Domo’s\\n\\nopen data platform can be used either as an organization’s primary data store or as an \\xa0augmentation to its existing stack.\\n\\nIT leaders can also take advantage of the web-based toolkit called Connector Dev Studio which \\xa0allows clients to customize connectors.\\n\\n# How Domo Connects \\xa0and Stores Your Data\\n\\n## Expand on Existing Feeds with the API\\n\\nUsers that prefer to bypass Domo’s connectors for some of their data can upload via the Domo \\xa0API and Java command line interface (CLI). These robust developer tools help more advanced \\xa0teams pull or push data programmatically. The multi-part API breaks multi-billion row updates \\xa0into many small segments for simultaneous processing. This high-bandwidth ingestion option \\xa0accelerates time to value and reduces switching costs no matter how large the initial import is.\\n\\n![](images/image11.png)The CLI can process data so quickly that IT no longer has to feel forced through a single data \\xa0pipeline path. Choose whether a direct or hybrid path best fits your use case and Domo \\xa0can adapt.\\n\\n## Expand Storage for the Endless Influx of Data\\n\\nAdrenaline is Domo’s intelligent data warehouse with sub-second response even for high \\xa0volumes of concurrent queries. Domo uses a massively scalable parallel processing query engine \\xa0that can handle any amount and any frequency of data—the only limitation comes from the \\xa0original source system. Moreover, Domo uses durable storage and\\n\\nredundant systems to provide the best possible experience to end\\n\\nusers. This open data framework gives IT multiple options for importing\\n\\nand exporting information. Management, metadata, and record-level\\n\\ndata governance are universally provided, no matter what the\\n\\nproprietary source and format of data. This frees IT from cumbersome\\n\\nmodeling requirements. While Domo can easily ingest multi-billion row datasets, you never need \\xa0to worry about duplication of or unnecessary replication of your data. Management of federated \\xa0queries gives IT explicit control of every table that can be accessed\\n\\nby Domo.\\n\\n## Simplify Storage Logistics with Federated Agents\\n\\nDomo embraces a variety of enterprise IT approaches to data management. Customers have \\xa0several options from full hosting in Domo, exclusive storage in the client’s data lake, or a hybrid \\xa0blend of both. Adrenaline’s data engine provides highly indexed and available data without the \\xa0need to constantly summarize and cube. Still, if there are parts of your data lake you would not \\xa0want to replicate, federated agents can create a cached version of the detailed raw data in your lake.\\n\\nThis federated approach solves data residency issues between the Domo cloud and your \\xa0on-premise data stores as the data remains within your lake but is accessible by Domo cards, \\xa0apps, and visualizations. The query is sent directly to your lake and translated from DQL (Domo \\xa0Query Language) to the SQL format of your current database technology. This can still be used in \\xa0conjunction with Adrenaline to ensure speed of most common queries while federated is used \\xa0for more complex views without having to worry about the logistics of duplicating large data sets. \\xa0Client-side machines can serve data for multiple adapters. Top database management \\xa0technologies like AWS, SQL Server, MySQL, and Crossdata are supported. Pending support is \\xa0being developed for Couchbase, Teradata, and Hadoop. New federated adapters are available \\xa0upon request. Dynamic load-balancing supports redundancy since the federated service code can \\xa0detect all the client-side agents. The federated service then redistributes queries based on what is \\xa0most active and is likely to respond fastest.\\n\\nMany Domo customers configure a bi-directional integration with their existing data lake so that \\xa0Domo can expand connections to the systems business users want most. Other customers use \\xa0Domo connectors for internal systems too, effectively creating their data lake in Domo. The rest \\xa0take a hybrid approach as Domo starts as a data mart that grows faster than any other because \\xa0of its speed, scale, security, and simplicity. All three approaches help IT departments realize great\\n\\ner value from their past investments.\\n\\n# Efficiency Plus Security\\n\\n## Keeping IT in Control\\n\\nEfficient storage and queries only matter if they are accompanied by top-level security. Domo \\xa0brings governance and security that you can trust no matter what the scenario. Within our \\xa0federated approach, for instance, a cache of the most recent queries is stored only long enough \\xa0to render visualizations during a customizable time to live. Time to live settings can also be \\xa0overridden with an immediate kill switch to flush the cache across all queries. This can actually \\xa0lower AWS costs by managing what gets placed in real time hot storage vs. long-term cold storage.\\n\\nAt rest, customer data in Domo is ephemeral. Only the sub-set of customer data that is queried \\xa0by the customer is passed temporarily to Domo. TTL (Time to live) associated with all customer \\xa0data can be configured by the customer to be as short as milliseconds. Once the TTL expires \\xa0after processing it is immediately deleted from \\xa0![](images/image10.png)\\n\\nmemory. Customers can totally disable data ac\\n\\ncess and delete all customer data in the Domo\\n\\ncloud anytime. Smart caching ensures repetitive\\n\\nrequests do not hit the DB again as long as they\\n\\nare made within the TTL.\\n\\nPersistent socket connections minimize traffic\\n\\nto avoid issues with latency that otherwise would have occurred due to re-establishing the TCP \\xa0connection for each request. The client has full control. They determine which connections to \\xa0initiate, which data to share, and how long to maintain the time to live. ![](images/image15.png)\\n\\nThis protects data in all \\xa0stages of its lifecycle.\\n\\nCustomer firewalls control all inbound and out\\n\\nbound traffic in-transit. All traffic is encrypted with\\n\\nstrong authentication to ensure system integrity.\\n\\nFederated clients are managed by the customer\\n\\nwithin their own data center to regulate every\\n\\naction. This gives security experts the assurance\\n\\nthey need to govern what is accessible to those\\n\\nexternal connections. IT can enforce detailed\\n\\nlimits so Domo can only query approved tables.\\n\\n![](images/image13.png)\\n\\n## Securely Share Data at Scale to Multiple Subscribers\\n\\nAll of the scale that Domo offers comes with granular row\\n\\nlevel control for access entitlements. Every dataset can\\n\\nhave an infinite number of permission policies that can all\\n\\nbe managed via API. Further enhance Domo governance\\n\\ncontrols with Publish, which can be used to mirror portions of content from a master parent \\xa0instance to any number of fully separated subscribers.\\n\\nThe subscriber instances have unique login portals to prevent any chance of access to restricted \\xa0data. Activity across all subscribers can be tracked within the Domo Publish page of the parent \\xa0instance. This is especially useful for IT teams that must manage sharing for multiple customers \\xa0and partners.\\n\\n![](images/image7.png)\\n\\n## Secure Sensitive Data with Complete Confidence\\n\\nOver 32% of the Fortune 50 Global companies (including many of the largest organization in \\xa0the US, Europe, Asia, and Australia) are served by the Domo cloud. Domo has built the Business \\xa0Cloud platform to meet the enterprise security, compliance, and privacy requirements of our \\xa0customers in highly regulated industries, such as financial services, health care, pharmaceuticals, \\xa0government, energy, and technology providers.\\n\\nTo ensure the requirements of customers and regulators are met, Domo completes numerous \\xa0audits, assessments and compliance requirements—including rigorous third-party network and \\xa0system penetration tests.\\n\\n![](images/image5.png)\\n\\nDomo’s enterprise-grade cloud architecture protects your most sensitive and confidential data, \\xa0even in highly-regulated verticals, like financial services and healthcare. The Domo Trust program \\xa0covers all your security, compliance, and privacy controls, offering 2FA, SSO, event logging, and \\xa0shared encryption keys that keep IT in control. Customers can control access down to individual \\xa0row of data through Personal Data Permissions (PDP).\\n\\nStrict segmentation is enforced with unique identifiers for all data and dedicated table \\xa0spaces. This is supported by multiple security layers, least privilege policies, and separation of \\xa0duty models, threat assessments of each new feature, transport layer encryption, encryption at \\xa0rest, customers management their own encryption keys, and extensive logging of system events.\\n\\n## Encryption ![](images/image8.png)\\n\\nIn transit, all interaction is forced through HTTPS and\\n\\nTLS. Workbench uses the same API calls that Domo web\\n\\nbrowser interface uses. Both require outbound TCP port\\n\\n443 from the client’s office. Public connectors, such as\\n\\nweather service data, may not be encrypted in transit if the\\n\\ndata provider does not make encryption options available.\\n\\nAll other connectors use encryption by default. At rest, all\\n\\ndata is immediately encrypted and stored in Vault for persistence, backup, and redundancy. It is \\xa0replicated across multiple redundant locations and transmission of the backup is also encrypted.\\n\\n## Retention\\n\\nDomo retains multiple versions of data. Most is kept for a year, while other types remain for up to \\xa0seven years. Domo will delete client data from our systems within 90 days of agreement \\xa0termination or upon valid customer request. This includes all backups and archives.\\n\\nDisaster recovery plans are in line with industry continuity standards and are updated annually \\xa0according to frequent SOC 2 tests. Domo does not distribute specific details as it contains cus tomer contact information and other protected data.\\n\\n## Location\\n\\nDomo is primarily deployed in the US East region of AWS. Domo’s platform is deployed across \\xa0multiple zones within the region for availability purposes. We also offer hosting in the Dublin and \\xa0Sydney AWS regions. Any activity outside of the US is optional, based on client need. \\xa0Other regions may be available in the future and utilized to comply with customer regulation \\xa0requirements.\\n\\nIn addition to AWS, Domo utilizes Equinix as another US-based data center provider. Domo leases \\xa0cage space separate from other Equinix customers, and we own and manage all the hardware \\xa0associated with our clients’ data. Cybage is the 24x7x365 Network Operations Center service \\xa0provider. Both organizations may have incidental access to customer data in supporting Domo’s \\xa0operational needs but are not provided direct access to customer data. Domo conducts third \\xa0party vendor assessments and annual security reviews of these vendors in-line with industry \\xa0leading practices.\\n\\n## BYOK ![](images/image4.png)\\n\\nBring Your Own Key provides peace of mind by giving IT\\n\\ncomplete control of the encryption keys. This helps IT\\n\\nensure data is always kept private, even from Domo. Cus\\n\\ntomers can revoke the encryption key at any time with an\\n\\ninstant kill switch that nullifies data access so sensitive data\\n\\nis safe.\\n\\nDomo BYOK is the first of its kind for enterprise cloud security in business intelligence. \\xa0It’s designed to let each customer manage their own cloud instance in accordance with internal \\xa0security and compliance requirements. Domo BYOK provides the ability to rotate the encryption \\xa0keys numerous times a day. Through this customer-controlled encryption, customers can revoke \\xa0encryption keys at any time, nullifying all data in Domo, and making it so no one will have access \\xa0to their sensitive customer data. With Domo BYOK, customers are always in complete control of \\xa0their data.\\n\\nSpecific fields or columns can be protected by a pre-shared key or a password. \\xa0The BYOK kill \\xa0switch allows 2 people to simultaneously approve deletion of the cache. Domo only receives the \\xa0encrypted data and never accesses the customer key. Since Domo cannot decrypt the data \\xa0without customer permission, clients control the distribution of the key to their users.\\n\\n## SAML-based SSO\\n\\nEnterprises that use identity providers can configure Domo as the endpoint URL and upload an \\xa0x.509 certificate to control access based on predefined user groups.\\n\\n![](images/image6.png)![](images/image12.png)\\n\\n## Multi-Factor Authentication\\n\\nLogin credential storage is salted with a SHA 512 hash in the CyberArk password management \\xa0system. Any support services team member who needs access to a credential must be pre-au thorized.\\xa0Internal specialists authenticate with their individual user account and a valid business \\xa0justification for change control, troubleshooting, scaling, or availability. All business justifications \\xa0are logged and reviewed daily by Information Security. Weekly reports detailing access are sent to \\xa0the client services management for review.\\n\\n## User Types\\n\\nCreating users and granting access rights in Domo is the first layer in maintaining information \\xa0security. Profiles either grant and/or restrict access to the specific data and apps in Domo. For \\xa0ease of deployment, pre-defined security profile options include Administrator, Privileged, Editor, \\xa0and Participant. Each profile contains clearly defined access privileges which can be turned on or \\xa0off by default. Role privileges can be fully tailored to align with your unique policies.\\n\\n## Personalized Data Permissions\\n\\nAuthorized users can create robust entitlement policies that govern access to specific data in a \\xa0data set for individuals or groups. With PDP, you can tailor data access permissions for each \\xa0specific user, increasing data usage while simultaneously ensuring that sensitive information \\xa0remains secure.\\n\\n![](images/image14.png)\\n\\n## Log Monitoring\\n\\nAdministrators can easily monitor global activity across Domo with the Domo-provided Activity \\xa0Logs console. One can quickly access usage metrics like login attempts, card views, card creation, \\xa0and card edits. The console also provides the times those events took place and by which user. \\xa0Admins can filter and sort this data, and export to an Excel spreadsheet or CSV file.\\n\\n![](images/image9.png)\\n\\n@domo.com\\n\\n# Expand on New Data \\xa0Opportunities\\n\\n## Standardize Formatting for Consistent Reliability\\n\\nFusion is Domo’s data transformation engine that ensures all data\\n\\nspeaks the same language. Fusion’s native data manipulation tools en\\n\\nable any connected dataset to be cleansed, combined and prepared\\n\\nwithout any outside ETL technologies. Domo’s Magic ETL enables less\\n\\nexperienced business users to format data from any source, with no\\n\\ncoding or SQL expertise required.\\n\\nFusion’s predictive algorithms and\\n\\ncustomizable code blocks unlock the\\n\\ntremendous value of data science. For\\n\\nexample, data from marketing automation and web analytics can\\n\\nbe transformed through drag and drop flows to uncover insights,\\n\\nperform calculations, and maintain accuracy. More advanced users\\n\\nstill have the option to write, edit, and validate SQL queries in\\n\\nDomo Data Flows.\\n\\nWhen imported data needs cleansing, standardization, or aggrega\\n\\ntion, scripts can be refined directly within Domo to transform data\\n\\nwithout having to switch back and forth between niche tools. Experts comfortable with MySQL \\xa0or Redshift will feel right at home coding a sub-select or join in Domo’s SQL editor to leverage its \\xa0scalable resources.\\n\\n## Drive Adoption with an Intuitive Interface for\\n\\nSelf-Serve Data Exploration\\n\\nWhile great for data science work and engineered solutions, most BI\\n\\ntools are too complicated for adoption by common business users.\\n\\nDomo’s Explorer provides a user-friendly interface to visualize data\\n\\nfrom your data lake. Ad hoc exploration is intuitive enough that any\\n\\nbusiness user can build and share real-time stories anywhere from\\n\\nboard meetings to weekly updates. This frees up data scientists to focus on truly advanced \\xa0analytics and makes data exploration intuitive for others across the business.\\n\\nBusiness leaders need access everywhere they work, so Domo\\n\\nmakes it easy to build once and interact anywhere with support for\\n\\nevery device across mobile and desktop. SMS text alerts with mo\\n\\nbile views are aligned with email alerts and desktop drill downs so\\n\\nyou can adapt everything from executive overviews through analyst\\n\\nexploration workspaces.\\n\\n## Mobile-first Means Build Once and Be Done\\n\\nEvery card built in Domo is automatically mobile-optimized\\n\\nfor whatever device you’re viewing it on, so you’ll never need\\n\\nto create or maintain a separate mobile version.\\n\\nThe fully-interactive mobile experience gives users access to\\n\\nlive business data and all the tools needed to explore, drill,\\n\\nanalyze, annotate, and comment on any device. Add critical\\n\\ncontext to your data with annotations drawn right on a chart\\n\\nto ask questions, call out anomalies, and sync automatically\\n\\nacross all devices.\\n\\n## Use Your Own Visualization Tools with ODBC\\n\\nODBC allows more advanced users to query any Domo dataset like a \\xa0common database table via HTTPS. It requires a Client ID and Client\\n\\nSecret for authentication.\\n\\nThen analytics specialists can continue to use any visualization\\n\\nplatform or on-premises system they prefer for ad hoc data explora\\n\\ntion while the majority of business users use Domo for intuitive data \\xa0interaction on any device.\\n\\n## Show Content in the Context of Internal Applications\\n\\nBypass the Domo Interface with Embed. For example, a call center application may pull in \\xa0customer profile cards from Domo. Business users want faster, more relevant data located \\xa0in the tools, sites, and applications they already use. Domo Everywhere \\xa0securely shares insights with customers, partners and vendors in\\n\\nportals, web properties, or applications.\\n\\nOnce embedded, any parameters applied to a card can be reflected\\n\\nin the embedded report. User access can also be controlled by using \\xa0personalized data permissions to pass parameters back to Domo.\\n\\n## Break Down Silos with Collaboration in Context\\n\\nBuzz is the integrated productivity tool for collaboration around important insights. Text messaging, video chat, sharing, and annotations foster a curiosity and puts qualitative information around quantitative data. Teams and individuals can share real-time data from any source,\\n\\ncreate team channels, and assign projects and tasks from within any\\n\\nconversation—all done quickly and securely.\\n\\nNow everyone can share and collaborate around business\\n\\ndata as a natural, organic part of the discussion. And it’s easily\\n\\naccessible from any screen in Domo, including mobile. Buzz is\\n\\navailable for free to every employee, and gives business users\\n\\none platform to use with co-workers, teams, departments,\\n\\nand across organizations.\\n\\n## Leverage Algorithms for \\xa0Actionable Automation\\n\\nMr. Roboto leverages machine learning algorithms, artificial intelligence and predictive analytics that\\n\\nconstantly scan incoming data to detect anomalies, identify correlations, and provide alerts.\\n\\nThis AI layer sits at the convergence of all the data and user\\xa0activities in Domo. This offers increased alignment, accuracy and effectiveness so that business decision makers can gain a holistic view of their data to take more informed actions.\\n\\nIn addition to predictive alerts sent via Buzz, Domo’s powerful data science tools can help users \\xa0get more out of their data investment. By combining tools such as anomaly detection, personal \\xa0data consumption patterns, trending focus points and more, Domo intelligently surfaces key \\xa0insights and anomalies for optimizing core business functions and predicting key challenges in \\xa0performance.\\n\\n## Manage by exception with predictive alerts\\n\\nGet notified via email, mobile push notifications, or text \\xa0when the business needs your attention. Focus on proac\\n\\ntive optimization while there’s still time to make an impact.\\n\\nAvoid noise by scheduling alerts for any frequency you \\xa0prefer. Time-based alerts also help you to set measurable \\xa0pacing goals and then be alerted when the progress you \\xa0expect is not on track.\\n\\nFor more advanced data scientists, R and Python integrations provide the flexibility they need to interact with their \\xa0models natively in Domo’s platform and focus less on data hygiene. Data science tools in Magic \\xa0ETL including ANOVA, ANCOVA, hierarchical clustering, K-means clustering, K-medians clustering, \\xa0logistic regression, multinomial regression, multivariate outliers, nonparametric outliers, OLS \\xa0regression, parametric outliers, and time series outliers. Maintaining focused action gets even \\xa0easier as Mr. Roboto detects deviations from the norm and automatically alerts users to any \\xa0significant irregularity.\\n\\n## Standardize Best Practices with Extensible Examples\\n\\nDomo’s AppStore makes it easy to leverage the expertise of Domo’s\\n\\npartner program and the developer community to personalize Domo\\n\\nand answer their specific business questions. The AppStore also allows\\n\\nDomo partners to quickly bring new data-driven solutions to market by\\n\\nleveraging the time-consuming tasks managed by Domo.\\n\\nDomo’s full App ecosystem provides hundreds of plug-and-play\\n\\ndashboards and apps targeted to meet the needs of a specific indus\\n\\ntry, functional role, or use-case scenario. In addition, Domo’s SDK and\\n\\nDesign Studio lets you build your own solution that meets your specific\\n\\nbusiness needs, while automatically integrating Domo’s native features\\n\\nlike collaboration and alerts.\\n\\n\\n\\nBuild powerful, custom apps that meet your specific business needs, while automatically integrat ing features like collaboration and alerts. Get your hands dirty with a free sandbox environment \\xa0to iterate and perfect your solutions. Many are already pre-loaded with sample data, example \\xa0cards, and extensive documentation. The API supports programmatic data and user management \\xa0so IT can integrate with existing MDM systems, active directories, and security policies.\\n\\n# Lead a Culture of\\n\\n# Curiosity in Digital \\xa0Transformation\\n\\nDomo sees consistent enterprise success when we partner together with business and IT \\xa0leaders from the start. That is why we are eager to answer any other questions you might have \\xa0about technical platform details and look forward to helping you with compatible fit, risk \\xa0mitigation, rollout support, and cost savings.\\n\\n## Compatible Fit\\n\\nArchitecture diagrams prove Domo can augment existing infrastructure investments. Even for \\xa0highly regulated industries, third-party certifications verify that Domo complies with strict \\xa0security and encryption requirements. Implementation can be completed in aggressive \\xa0deadlines, especially when combined with a proof of concept.\\n\\n## Risk Mitigation\\n\\nSensitive data can be isolated and safely stored in Domo. IT has full control over user access to \\xa0each version of data with personalized data permissions and bulk entitlement governance. IT can \\xa0easily monitor who has been utilizing that access with detailed logs. Domo’s customers operate \\xa0in every industry around the globe including highly regulated verticals such as Financial Services \\xa0and Healthcare.\\n\\n## Rollout Support\\n\\nIT can trust Domo to scale to concurrent queries on billions of rows with sub-second responses. \\xa0IT leaders can easily standardize Domo usage across the company with best practice templates. \\xa0Content that needs maintenance is highlighted with a health scorecard that shows what is being \\xa0used most and what sources have been validated.\\n\\n## Cost Savings\\n\\nDomo unlocks value from the millions already invested in business intelligence and analytics. \\xa0Measure the dramatically increased adoption of your current systems once Domo provides the \\xa0capstone to your data strategy through last-mile business intelligence.\\n\\nWe invite IT leaders everywhere to test what true digital transformation looks like through a \\xa0proof of concept. The experienced Domo services team will help IT infuse digitally connected \\xa0teams with data. With Domo, IT can accelerate digital transformation and infuse a culture of \\xa0innovation and curiosity throughout the entire organization.\\n\\n—\\n\\nConfluence [Link](https://www.google.com/url?q=https://confluence.sie.sony.com/display/DOMO/Domo%2BIT%2BWhitepaper%2B-%2BWhat%2Bis%2BDomo&sa=D&source=editors&ust=1741268390270866&usg=AOvVaw29EU38fw0caWxQIlowv2_A)\\n\\nGoogle Doc [Link](https://www.google.com/url?q=https://docs.google.com/document/d/1ceYCBm8Zn_2_wLb0EQRsTu_NIYnW_QAuQtjTQhDNA1g/edit&sa=D&source=editors&ust=1741268390271167&usg=AOvVaw1JDhXIYJKg3w0eowrvUlBB)\\n\\n[Self GDoc](https://docs.google.com/document/d/1ceYCBm8Zn_2_wLb0EQRsTu_NIYnW_QAuQtjTQhDNA1g/edit?usp=drivesdk)\\n',\n",
                            "  'metadata': {},\n",
                            "  'embedding': None,\n",
                            "  'created_at': '2025-03-17T23:20:51.715298+00:00'}]"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "with open('../../TEST/storage_routes/test_upload.md' , 'r', encoding = 'utf-8') as f:\n",
                "    data = f.read()\n",
                "        \n",
                "res = store_data_in_supabase_table(\n",
                "    table_name = \"site_pages\",\n",
                "    data = {\n",
                "        \"url\" : \"test.md\",\n",
                "        \"chunk_number\" : 0,\n",
                "        \"title\": \"Domo IT Whitepaper\",\n",
                "        \"summary\" : \"a whitepaper a about IT\",\n",
                "        \"content\": data},\n",
                "    supabase_client= supabase_client\n",
                ")\n",
                "\n",
                "res.response\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# | export\n",
                "\n",
                "\n",
                "def save_chunk_to_disk(\n",
                "    output_path,\n",
                "    data: dict,\n",
                "    **kwargs,\n",
                "):\n",
                "\n",
                "    amfi.upsert_folder(output_path)\n",
                "\n",
                "    url = data[\"url\"]\n",
                "    source = data[\"source\"]\n",
                "    content = data[\"content\"]\n",
                "    title = data.get(\"title\")\n",
                "    summary = data.get(\"summary\")\n",
                "    embedding = data.get(\"embedding\")\n",
                "    metadata = data.get(\"metadata\")\n",
                "    chunk_number = data.get(\"chunk_number\")\n",
                "\n",
                "    output_ls = [\n",
                "        \"---\",\n",
                "        f\"url: {url}\",\n",
                "        f\"session_id: {source}\",\n",
                "        f\"chunk_number: {chunk_number}\" if chunk_number is not None else None,\n",
                "        f\"title: {title}\" if title is not None else None,\n",
                "        f\"summary: {summary}\" if summary is not None else None,\n",
                "        f\"embedding: {embedding}\" if embedding is not None else None,\n",
                "        f\"metadata : {json.dumps(metadata)}\" if metadata is not None else None,\n",
                "        f\"updated_dt: {dt.datetime.now().isoformat()}\",\n",
                "        \"---\",\n",
                "        content,\n",
                "    ]\n",
                "\n",
                "    with open(output_path, \"w+\", encoding=\"utf-8\") as f:\n",
                "        f.write(\"\\n\".join([row for row in output_ls if row is not None]))\n",
                "\n",
                "        return True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "save_chunk_to_disk(output_path = \"../../TEST/storage_routes/save_to_disk.md\",data = {\"source\" : 'test',**res.response[0], \n",
                "                                                                                     })"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| hide\n",
                "nbdev.nbdev_export('/.storage.ipynb')"
            ]
        }
    ],
    "metadata": {
        "jupytext": {
            "split_at_heading": true
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
