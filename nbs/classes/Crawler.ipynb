{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| default_exp classes.Crawler_ProcessedChunk"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CRAWLER\n",
                "> Cralwer uses crawl4ai to download websites as markdown content"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| export\n",
                "from dataclasses import dataclass, field\n",
                "import os\n",
                "from openai import AsyncOpenAI\n",
                "\n",
                "import agent_mafia.routes.openai as openai_routes\n",
                "import agent_mafia.routes.storage as storage_routes\n",
                "import agent_mafia.prompts.crawler as crawler_prompts\n",
                "\n",
                "import agent_mafia.client.MafiaError as amme\n",
                "import agent_mafia.utils.files as amfi\n",
                "\n",
                "from typing import Union, List\n",
                "from urllib.parse import urlparse\n",
                "import datetime as dt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| export\n",
                "@dataclass\n",
                "class Crawler_ProcessedChunk_Metadata:\n",
                "    source: str\n",
                "    crawled_at: str\n",
                "    url_path: str\n",
                "    chunk_size: int\n",
                "\n",
                "    @classmethod\n",
                "    def from_url(cls, source, chunk: str, url):\n",
                "        return cls(\n",
                "            source=source,\n",
                "            crawled_at=dt.datetime.now().isoformat(),\n",
                "            url_path=urlparse(url).path,\n",
                "            chunk_size=len(chunk),\n",
                "        )\n",
                "\n",
                "    def to_json(self):\n",
                "        return {\n",
                "            \"source\": self.source,\n",
                "            \"crawled_at\": self.crawled_at,\n",
                "            \"url_path\": self.url_path,\n",
                "            \"chunk_size\": self.chunk_size,\n",
                "        }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| export\n",
                "\n",
                "class PC_PathNotExist(amme.MafiaError):\n",
                "    def __init__(self, md_path):\n",
                "        super().__init__(f\"path {md_path} does not exist\")\n",
                "\n",
                "@dataclass\n",
                "class Crawler_ProcessedChunk:\n",
                "    source: str # where a piece of data came from (e.g. a session_id) // could be a complete website or subject area\n",
                "    url: str\n",
                "    chunk_number: int\n",
                "    content: str = field(repr=False) # the actual data \n",
                "    title: str = None\n",
                "    summary: str = None\n",
                "    embedding: List[float] = None\n",
                "    metadata: Union[Crawler_ProcessedChunk_Metadata, None] = None\n",
                "    async_client: Union[AsyncOpenAI, None] = field(repr=False, default=None)\n",
                "    error_logs: List[str] = field(default_factory=list)\n",
                "\n",
                "    def __eq__(self, other):\n",
                "        if self.__class__.__name__ != other.__class__.__name__:\n",
                "            return False\n",
                "\n",
                "        return self.url == other.url and self.chunk_number == other.chunk_number\n",
                "\n",
                "    def __post_init__(self):\n",
                "        self.metadata = Crawler_ProcessedChunk_Metadata.from_url(\n",
                "            url=self.url,\n",
                "            source=self.source,\n",
                "            chunk=self.content,\n",
                "        )\n",
                "\n",
                "    @classmethod\n",
                "    def from_chunk(\n",
                "        cls, chunk: str, chunk_number: int, url: str, source: str, output_path=None\n",
                "    ):\n",
                "\n",
                "        chunk = cls(\n",
                "            url=url,\n",
                "            chunk_number=chunk_number,\n",
                "            source=source,\n",
                "            content=chunk,\n",
                "        )\n",
                "\n",
                "        if output_path:\n",
                "            chunk.compare_self_to_disk(output_path)\n",
                "\n",
                "        return chunk\n",
                "\n",
                "    @classmethod\n",
                "    def from_md_file(cls, md_path):\n",
                "        if not os.path.exists(md_path):\n",
                "            raise PC_PathNotExist(md_path)\n",
                "\n",
                "        try:\n",
                "            chunk, frontmatter = amfi.read_md_from_disk(md_path)\n",
                "\n",
                "            res = cls(\n",
                "                url=frontmatter.get(\"url\"),\n",
                "                source=frontmatter.get(\"session_id\"),\n",
                "                chunk_number=frontmatter.get(\"chunk_number\"),\n",
                "                title=frontmatter.get(\"title\"),\n",
                "                summary=frontmatter.get(\"summary\"),\n",
                "                embedding=frontmatter.get(\"embedding\"),\n",
                "                content=chunk,\n",
                "            )\n",
                "\n",
                "            return res\n",
                "\n",
                "        except amme.MafiaError as e:\n",
                "            print(e)\n",
                "            return False\n",
                "\n",
                "    def compare_self_to_disk(self, md_path):\n",
                "        if not os.path.exists(md_path):\n",
                "            return False\n",
                "        \n",
                "        try:\n",
                "            md_chunk = self.from_md_file(md_path=md_path)\n",
                "\n",
                "        except PC_PathNotExist as e:\n",
                "            print(e)\n",
                "            return self\n",
                "\n",
                "        if not md_chunk:\n",
                "            return self\n",
                "\n",
                "        if md_chunk.content == self.content:\n",
                "            self.title = self.title or md_chunk.title\n",
                "            self.summary = self.summary or md_chunk.summary\n",
                "            self.embedding = self.embedding or md_chunk.embedding\n",
                "            self.metadata = md_chunk.metadata\n",
                "            self.error_logs = md_chunk.error_logs\n",
                "\n",
                "        return self\n",
                "\n",
                "    async def get_title_and_summary(\n",
                "        self,\n",
                "        is_replace_llm_metadata: bool = False,\n",
                "        async_client: AsyncOpenAI = None,\n",
                "        model=\"gpt-4o-mini-2024-07-18\",\n",
                "        debug_prn: bool = False,\n",
                "        return_raw: bool = False,\n",
                "    ) -> dict:\n",
                "\n",
                "        async_client = async_client or openai_routes.default_async_openai_client\n",
                "\n",
                "        if not is_replace_llm_metadata and self.title and self.summary:\n",
                "            if debug_prn:\n",
                "                print(f\"üõ¢Ô∏è {self.url} title and summary already exists\")\n",
                "            return self\n",
                "\n",
                "        system_prompt = crawler_prompts.prompt_extract_title_and_summary\n",
                "\n",
                "        messages = [\n",
                "            {\"role\": \"system\", \"content\": system_prompt},\n",
                "            {\n",
                "                \"role\": \"user\",\n",
                "                \"content\": f\"URL: {self.url}\\n\\nContent:\\n{self.content[:1000]}...\",\n",
                "            },  # Send first 1000 chars for context\n",
                "        ]\n",
                "        try:\n",
                "            res = await openai_routes.generate_openai_chat(\n",
                "                messages=messages,\n",
                "                async_client=async_client,\n",
                "                model=model,\n",
                "                response_format={\"type\": \"json_object\"},\n",
                "                return_raw=return_raw,\n",
                "            )\n",
                "\n",
                "            if return_raw:\n",
                "                return res\n",
                "\n",
                "            self.title = res.response.get(\"title\")\n",
                "            self.summary = res.response.get(\"summary\")\n",
                "\n",
                "            return res\n",
                "\n",
                "        except amme.MafiaError as e:\n",
                "            message = f\"Error getting title and summary: {e}\"\n",
                "\n",
                "            print(message)\n",
                "            self.error_logs.append(message)\n",
                "\n",
                "            return False\n",
                "\n",
                "    async def get_embedding(\n",
                "        self,\n",
                "        is_replace_llm_metadata: bool = False,\n",
                "        async_client: AsyncOpenAI = None,\n",
                "        model=\"text-embedding-3-small\",\n",
                "        return_raw: bool = False,\n",
                "        debug_prn: bool = False,\n",
                "    ) -> List[float]:\n",
                "\n",
                "        if not is_replace_llm_metadata and self.embedding:\n",
                "\n",
                "            if debug_prn:\n",
                "                print(f\"üõ¢Ô∏è  {self.url} embedding already retrieved\")\n",
                "\n",
                "            return self\n",
                "\n",
                "        try:\n",
                "            res = await openai_routes.generate_openai_embedding(\n",
                "                text=self.content,\n",
                "                async_client=async_client,\n",
                "                model=model,\n",
                "                return_raw=return_raw,\n",
                "                debug_prn=debug_prn,\n",
                "            )\n",
                "\n",
                "            if return_raw:\n",
                "                return res\n",
                "\n",
                "            self.embedding = res\n",
                "            return res\n",
                "\n",
                "        except amme.MafiaError as e:\n",
                "            message = f\"Error creating embedding: {e}\"\n",
                "\n",
                "            self.error_logs.append(message)\n",
                "\n",
                "            return False\n",
                "\n",
                "    async def generate_metadata(\n",
                "        self,\n",
                "        is_replace_llm_metadata: bool = False,\n",
                "        async_text_client: AsyncOpenAI = None,\n",
                "        async_embedding_model: AsyncOpenAI = None,\n",
                "        text_model=\"gpt-4o-mini-2024-07-18\",\n",
                "        embedding_model=\"text-embedding-3-small\",\n",
                "        debug_prn: bool = False,\n",
                "        output_path: str = None,\n",
                "    ):\n",
                "        await self.get_title_and_summary(\n",
                "            is_replace_llm_metadata=is_replace_llm_metadata,\n",
                "            async_client=async_text_client,\n",
                "            model=text_model,\n",
                "            debug_prn=debug_prn,\n",
                "        )\n",
                "        await self.get_embedding(\n",
                "            is_replace_llm_metadata=is_replace_llm_metadata,\n",
                "            async_client=async_embedding_model,\n",
                "            model=embedding_model,\n",
                "            debug_prn=debug_prn,\n",
                "        )\n",
                "\n",
                "        if output_path:\n",
                "            storage_routes.save_chunk_to_disk(output_path=output_path,\n",
                "                                              data = self.to_json())\n",
                "\n",
                "        return self\n",
                "\n",
                "    def to_json(self):\n",
                "        return {\n",
                "            \"url\": self.url,\n",
                "            \"source\": self.source,\n",
                "            \"chunk_number\": self.chunk_number,\n",
                "            \"title\": self.title or \"No Title\",\n",
                "            \"summary\": self.summary or \"No Summary\",\n",
                "            \"content\": self.content,\n",
                "            \"metadata\": self.metadata.to_json(),\n",
                "            \"embedding\": self.embedding or [0] * 1536,\n",
                "        }"
            ]
        }
    ],
    "metadata": {
        "jupytext": {
            "split_at_heading": true
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
