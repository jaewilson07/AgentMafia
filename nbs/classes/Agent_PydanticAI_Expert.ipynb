{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# default_exp classes.Agent_PydanticAI_Expert"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Default Title (change me)\n", "> Default description (change me)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#export\n", "import os\n", "from dataclasses import dataclass\n", "\n", "from typing import List\n", "\n", "from supabase import Client as SupabaseClient\n", "from openai import AsyncClient\n", "\n", "from pydantic_ai import Agent, RunContext\n", "from pydantic_ai.models.openai import OpenAIModel\n", "\n", "import utils\n", "\n", "from src.prompts.agent import pydantic_agent_system_prompt\n", "from src.routes.openai import generate_openai_embbedding"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#export\n", "llm = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini-2024-07-18\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#export\n", "model = OpenAIModel(llm)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#export\n", "def format_supabase_chunks(data: List[dict]):\n", "    return [\n", "        f\"\"\"\n", "# {doc['title']}\n", "\n", "{doc['content']}\n", "            \"\"\"\n", "        for doc in data\n", "    ]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#export\n", "def format_supabase_page(data: List[dict]):\n", "    page_title = data[0][\"title\"].split(\" - \")[0]\n", "\n", "    formatted_content = [f\"# {page_title}\\n\"]\n", "\n", "    for chunk in data:\n", "        formatted_content.append(chunk[\"content\"])\n", "\n", "    return \"\\n\\n\".join(formatted_content)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#export\n", "@dataclass\n", "class PydanticAIDependencies:\n", "    supabase: SupabaseClient\n", "    openai_client: AsyncClient"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#export\n", "pydantic_ai_expert = Agent(\n", "    model=model,\n", "    system_prompt=pydantic_agent_system_prompt,\n", "    deps_type=PydanticAIDependencies,\n", "    retries=2,\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#export\n", "@pydantic_ai_expert.tool\n", "async def retrieve_llm(ctx: RunContext[PydanticAIDependencies], user_query: str) -> str:\n", "    \"\"\"\n", "    Retrieve relevant documentation chunks based on the query with RAG.\n", "\n", "    Args:\n", "        ctx: The context including the Supabase client and OpenAI client\n", "        user_query: The user's question or query\n", "\n", "    Returns:\n", "        A formatted string containing the top 5 most relevant documentation chunks\n", "    \"\"\"\n", "\n", "    try:\n", "        query_embedding = await generate_openai_embbedding(\n", "            user_query, ctx.deps.openai_client\n", "        )\n", "\n", "        # Query Supabase for relevant documents\n", "        result = ctx.deps.supabase.rpc(\n", "            \"match_site_pages\",\n", "            {\n", "                \"query_embedding\": query_embedding,\n", "                \"match_count\": 5,\n", "                \"filter\": {\"source\": \"pydantic_ai_docs\"},\n", "            },\n", "        ).execute()\n", "\n", "        data = result.data\n", "\n", "        if not data:\n", "            return \"No relevant documentation found.\"\n", "\n", "        formatted_chunks = format_supabase_chunks(data=data)\n", "\n", "        return \"\\n\\n---\\n\\n\".join(formatted_chunks)\n", "\n", "    except Exception as e:\n", "        message = utils.generate_error_message(e)\n", "        print(message)\n", "        return message"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#export\n", "@pydantic_ai_expert.tool\n", "async def list_documentation_pages(\n", "    ctx: RunContext[PydanticAIDependencies],\n", ") -> List[str]:\n", "    \"\"\"\n", "    Retrieve a list of all available Pydantic AI documentation pages.\n", "\n", "    Returns:\n", "        List[str]: List of unique URLs for all documentation pages\n", "    \"\"\"\n", "\n", "    try:\n", "        result = (\n", "            ctx.deps.supabase.from_(\"site_pages\")\n", "            .select(\"url\")\n", "            .eq(\"metadata->>source\", \"pydantic_ai_docs\")\n", "            .execute()\n", "        )\n", "\n", "        if not result.data:\n", "            return []\n", "\n", "        urls = sorted(set(doc[\"url\"] for doc in result.data))\n", "        return urls\n", "\n", "    except Exception as e:\n", "        message = utils.generate_error_message(\n", "            message=\"error retrieving documentation pages\", exception=e\n", "        )\n", "\n", "        print(message)\n", "\n", "        return []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#export\n", "@pydantic_ai_expert.tool\n", "async def get_page_content(ctx: RunContext[PydanticAIDependencies], url: str) -> str:\n", "    \"\"\"\n", "    Retrieve the full content of a specific documentation page by combining all its chunks.\n", "\n", "    Args:\n", "        ctx: The context including the Supabase client\n", "        url: The URL of the page to retrieve\n", "\n", "    Returns:\n", "        str: The complete page content with all chunks combined in order\n", "    \"\"\"\n", "\n", "    try:\n", "        result = (\n", "            ctx.deps.supabase.from_(\"site_pages\")\n", "            .select(\"title, content, chunk_number\")\n", "            .eq(\"url\", url)\n", "            .eq(\"metadata->>source\", \"pydantic_ai_docs\")\n", "            .order(\"chunk_number\")\n", "            .execute()\n", "        )\n", "\n", "        data = result.data\n", "\n", "        if not data:\n", "            return f\"No content found for URL: {url}\"\n", "\n", "        return format_supabase_page(data)\n", "\n", "    except Exception as e:\n", "        message = utils.generate_error_message(\n", "            message=\"error retrieving page content\", exception=e\n", "        )\n", "        print(message)\n", "\n", "        return message"]}], "metadata": {"jupytext": {"split_at_heading": true}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 4}